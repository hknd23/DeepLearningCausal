% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deep_meta_learners.R
\name{metalearner_deeplearning}
\alias{metalearner_deeplearning}
\title{metalearner_deeplearning
#' @description
\code{metalearner_deeplearning} implements the meta learners for estimating
CATE using Deep Neural Networks through Tensorflow.}
\usage{
metalearner_deeplearning(
  data = NULL,
  train.data = NULL,
  test.data = NULL,
  cov.formula,
  treat.var,
  meta.learner.type,
  nfolds = 5,
  algorithm = "adam",
  hidden.layer = c(2, 2),
  hidden_activation = "relu",
  output_activation = "linear",
  output_units = 1,
  loss = "mean_squared_error",
  metrics = "mean_squared_error",
  epoch = 10,
  verbose = 1,
  batch_size = 32,
  validation_split = NULL,
  patience = NULL,
  dropout_rate = NULL,
  conformal = FALSE,
  alpha = 0.1,
  calib_frac = 0.5,
  seed = 1234
)
}
\arguments{
\item{data}{data.frame object of data.}

\item{cov.formula}{formula description of the model y ~ x(list of covariates).}

\item{treat.var}{string for name of Treatment variable}

\item{meta.learner.type}{string of "S.Learner", "T.Learner", "X.Learner", or "R.Learner"}

\item{nfolds}{integer for number of folds for Meta Learners}

\item{algorithm}{string for optimization algorithm. For optimizers available see \code{keras} package.}

\item{hidden.layer}{vector specifying the hidden layers in the model and the number of neurons in each hidden layer.}

\item{hidden_activation}{string or vector for name of activation function for hidden layers of  model. Defaults to "relu".}

\item{output_activation}{string for name of activation function for output layer of  model.
"linear" is recommended for continuous outcome variables, and "sigmoid" for binary outcome variables.
For activation functions available see \code{keras} package.}

\item{output_units}{integer for units in output layer. Defaults to 1 for continuous and binary outcome variables.
In case of multinomial outcome variable, set to the number of categories.}

\item{loss}{string for loss function "mean_squared_error" recommended for linear models,
"binary_crossentropy" for binary models.}

\item{metrics}{string for metrics in response model. "mean_squared_error" recommended for linear models,
"binary_accuracy" for binary models.}

\item{epoch}{interger for number of epochs.}

\item{verbose}{integer specifying the verbosity level during training.
1 for full information and learning curve plots. 0 to suppress messages and plots.}

\item{batch_size}{integer for batch size to split training data.}

\item{validation_split}{double for proportion of training data to split for validation.}

\item{patience}{integer for number of epochs with no improvement to wait before stopping training.}

\item{dropout_rate}{double or vector for proportion of hidden layer to drop out.}

\item{conformal}{logical for whether to compute conformal prediction intervals}

\item{alpha}{proportion for conformal prediction intervals}

\item{calib_frac}{fraction of training data to use for calibration in conformal inference}

\item{seed}{random seed}
}
\value{
\code{metalearner_deeplearning} object with CATEs
}
\description{
metalearner_deeplearning
#' @description
\code{metalearner_deeplearning} implements the meta learners for estimating
CATE using Deep Neural Networks through Tensorflow.
}
